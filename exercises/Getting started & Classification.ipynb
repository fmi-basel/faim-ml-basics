{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split_frac=0.7):\n",
    "    '''load and split into training and test.\n",
    "\n",
    "    '''\n",
    "    data = seaborn.load_dataset('iris')\n",
    "    \n",
    "    # split for training and test\n",
    "    training = data.sample(frac=split_frac, random_state=0)\n",
    "    test = data.drop(training.index)\n",
    "    return training, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data, test_data = load_data(0.2)\n",
    "\n",
    "print('Training samples: {}'.format(len(training_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(training_data.head(10))\n",
    "\n",
    "seaborn.pairplot(training_data, hue='species')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first have to prepare the dataset for training. \n",
    "Scikit-learn estimators expect an array with input features and, in the case of a supervised method, an array with the corresponding targets.\n",
    "Besides, the class labels are currently strings, which we'll encode with an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def prepare_for_training(data):\n",
    "    '''removes the target column from the dataframe and encodes\n",
    "    classes with integers from [0, .., n-1]\n",
    "    '''\n",
    "    target_col = 'species'\n",
    "    features = data.drop(columns=target_col)\n",
    "    labels = LabelEncoder().fit_transform(data[target_col])\n",
    "    return features, labels\n",
    "\n",
    "\n",
    "train_features, train_labels = prepare_for_training(training_data)\n",
    "print('Feature shape:', train_features.shape)\n",
    "print('Label shape: ', train_labels.shape)\n",
    "\n",
    "print(train_features.head())\n",
    "print(train_labels[:5])\n",
    "\n",
    "plt.bar(np.unique(train_labels), np.bincount(train_labels))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a classifier and predicting with it\n",
    "\n",
    "We'll start with a simple k-nearest neighbours classifier ```KNeighborsClassifier```. In scikit-learn, all estimators use\n",
    "\n",
    "```\n",
    "clf.fit(...)\n",
    "```\n",
    "\n",
    "for fitting the model to the given training data and\n",
    "\n",
    "```\n",
    "clf.predict(...)\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```\n",
    "clf.predict_proba(...)\n",
    "```\n",
    "\n",
    "for predicting with a fitted (i.e. trained) estimator. The parametrization of the algorithm happens typically in the constructor or through ```set_params```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(6)  # TODO Replace\n",
    "classifier.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(labels_true, labels_pred):\n",
    "    '''a convenience function to plot the confusion matrix of predicted and true labels,\n",
    "    and run the \"classification_report\".\n",
    "\n",
    "    '''\n",
    "    coom = confusion_matrix(labels_true, labels_pred)\n",
    "\n",
    "    _, axarr = plt.subplots(\n",
    "        2, 2, \n",
    "        gridspec_kw=dict(width_ratios=[3, 1], height_ratios=[3, 1], hspace=0.25), \n",
    "        figsize=(8, 8), sharey='row', sharex='col')\n",
    "    \n",
    "    axarr[0, 0].matshow(coom)\n",
    "    axarr[0, 0].set_xlabel('Predicted')\n",
    "    axarr[0, 0].set_ylabel('True')\n",
    "    \n",
    "    color_threshold = 0.5 * (coom.max() - coom.min()) + coom.min()\n",
    "    for ii, jj in itertools.product(*[range(dim) for dim in coom.shape]):\n",
    "        val = coom[jj, ii]\n",
    "        axarr[0, 0].text(ii, jj, '{}'.format(val),  # beware of the coordinate system flip. \n",
    "                 horizontalalignment='center', \n",
    "                 color='white' if val < color_threshold else 'black')\n",
    "\n",
    "    axarr[0, 1].barh(np.arange(np.max(labels_true) + 1), np.bincount(labels_true))\n",
    "    axarr[0, 1].set_title('True labels')\n",
    "#     axarr[0, 1].invert_yaxis()\n",
    "\n",
    "    axarr[1, 0].bar(np.arange(np.max(labels_pred) + 1), np.bincount(labels_pred))\n",
    "    axarr[1, 0].set_title('Predicted labels')\n",
    "    \n",
    "    axarr[1, 1].axis('off')\n",
    "    dx = 0.5\n",
    "    axarr[0, 0].set_xlim(-dx, coom.shape[0]-dx)\n",
    "    axarr[1, 0].set_xlim(-dx, coom.shape[0]-dx)\n",
    "    axarr[0, 0].set_ylim(-dx, coom.shape[1]-dx)\n",
    "    axarr[0, 1].set_ylim(-dx, coom.shape[1]-dx)\n",
    "    \n",
    "    print(classification_report(labels_true, labels_pred))\n",
    "    print('Accuracy: {:1.2f}'.format(np.diag(coom).sum() / len(labels_true)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is the performance on the training set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(train_labels, \n",
    "                      classifier.predict(train_features))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring performance on the training set is going to be overly optimistic.\n",
    "\n",
    "We should estimate the performance with a validation split. ```scikit-learn```\n",
    "actually already provides us with utility functions to run a cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv_scores = cross_validate(classifier, \n",
    "                           train_features, \n",
    "                           train_labels, \n",
    "                           cv=10,\n",
    "                           return_train_score=True)\n",
    "\n",
    "for key in ['train_score', 'test_score']:\n",
    "    print('{}:\\n\\tmean={:1.3f}\\n\\tsplits=[{}]'.format(\n",
    "        key, np.mean(cv_scores[key]), ', '.join('{:1.3f}'.format(val) for val in cv_scores[key])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "* Choose another classifier from ```scikit-learn``` ([here](https://scikit-learn.org/stable/modules/classes.html)) and replace the ```kNearestNeighbours``` in the above code with it. \n",
    "    * What are it's main hyperparameters?\n",
    "    * How do they affect the outcome on the validation split?\n",
    "    * What does it mean in terms of model complexity?\n",
    "\n",
    "* Crossvalidation is a great way to optimize hyperparameters. Again, ```scikit-learn``` provides utility functions that are tailored to this. Have a look a the documentation for [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) and use it to tune the main parameter(s) of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# TODO ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final test\n",
    "\n",
    "Finally, let's measure the performance on the test set. How does it compare to your training  and validation performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError(\"Are you sure you already want to test your classifier?\")  # TODO comment out\n",
    "\n",
    "print('Test samples: {}'.format(len(test_data)))\n",
    "test_features, test_labels = prepare_for_training(test_data)\n",
    "\n",
    "print(test_features.shape, test_labels.shape)\n",
    "\n",
    "plot_confusion_matrix(test_labels, classifier.predict(test_features))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ML)",
   "language": "python",
   "name": "ml-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
